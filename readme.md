# ğŸ–ï¸ Sign Language Detection using MediaPipe & LSTM

A real-time sign language detection project that uses a webcam to track hand and body movements with MediaPipe Holistic, and an LSTM model to recognize sign language gestures from motion sequences.
The system supports data collection, training, evaluation, and real-time prediction using a webcam.

## Features

- Real-time sign language detection using a webcam
- MediaPipe Holistic for:
  - Pose landmarks
  - Hand landmarks
  - Face landmarks
- LSTM-based deep learning model for sequence classification
- Modular, clean, and extensible project structure
- Easy to add new signs and retrain the model
- TensorBoard logging support

## Requirements

## Software

- Python 3.7 or higher

```bash 
pip install numpy opencv-python mediapipe tensorflow scikit-learn
```

## Or use the recommended requirements.txt:

```bash
pip install -r requirements.txt
```

## ğŸ“ Project Structure

## Project Structure

- **signdetection/**
  - **src/** â€“ Core application logic  
    - `config.py` â€“ Central configuration  
    - `mediapipe_utils.py` â€“ MediaPipe detection helpers  
    - `data_utils.py` â€“ Data loading and preprocessing  
    - `model_utils.py` â€“ LSTM model definition  
    - `visualization.py` â€“ Drawing and visualization helpers  

  - **scripts/** â€“ Executable scripts  
    - `collect_data.py` â€“ Dataset collection  
    - `train_model.py` â€“ Model training  
    - `evaluate_model.py` â€“ Model evaluation  
    - `realtime_detection.py` â€“ Real-time sign detection  

  - **MP_Data/** â€“ Collected dataset (auto-created)
  - `README.md`
  - `.gitignore`
  - `requirements.txt`
